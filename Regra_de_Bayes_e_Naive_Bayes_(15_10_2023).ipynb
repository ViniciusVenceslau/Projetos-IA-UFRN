{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Regra de Bayes** & **Naive Bayes** - Python (15/10/2023)\n",
        "\n",
        "**Discente:** Vinícius Venceslau Venancio da Penha\n",
        "\n",
        "**Docente:** José Alfredo Ferreira Costa\n",
        "\n",
        "**ELE0606** - Tópicos Especiais em IA"
      ],
      "metadata": {
        "id": "UczsAzMhpX6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Base de Dados - **WINE**:"
      ],
      "metadata": {
        "id": "1GJL3pCKpqDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR62l9DZCxu4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Carregar o conjunto de dados Wine:\n",
        "wine_data = load_wine()\n",
        "wine_df = pd.DataFrame(wine_data['data'], columns=wine_data['feature_names'])\n",
        "wine_df['classe'] = wine_data['target']  # Adicionar a coluna de classe\n",
        "\n",
        "#Preparar os dados:\n",
        "X = wine_df.drop('classe', axis=1).to_numpy()\n",
        "y = wine_df['classe'].to_numpy()\n",
        "\n",
        "#Normalizar os dados:\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#Dividir os dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Inicializar a matriz de probabilidades:\n",
        "num_classes = len(np.unique(y))\n",
        "probabilidadeDaClasse = np.zeros(num_classes)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    probabilidadeDaClasse[i] = len(indiceDaClasse[0]) / len(y_train)\n",
        "\n",
        "#Matriz para armazenar as probabilidades de classe para cada observação de teste:\n",
        "matrizProbabilidade = np.zeros((X_test.shape[0], num_classes))\n",
        "\n",
        "#Calcular as probabilidades de classe para as observações de teste:\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    dadosDeTreino = X_train[indiceDaClasse]\n",
        "    media = np.mean(dadosDeTreino, axis=0)\n",
        "    covariancia = np.cov(dadosDeTreino, rowvar=False)\n",
        "\n",
        "    for j in range(X_test.shape[0]):\n",
        "        observation = X_test[j]\n",
        "        matrizProbabilidade[j, i] = multivariate_normal.pdf(observation, mean=media, cov=covariancia, allow_singular=True) * probabilidadeDaClasse[i]\n",
        "\n",
        "#Prever as classes com base nas probabilidades:\n",
        "y_pred = np.argmax(matrizProbabilidade, axis=1)\n",
        "\n",
        "#Calcular a acurácia das previsões:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy:.4f}')\n",
        "\n",
        "#Gerar Matriz Confusao\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1', 'Classe 2'])\n",
        "\n",
        "print(\"\\nMatriz de Confusao:\\n\", confusion)\n",
        "print(\"\\nRelatorio de Classificacao:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Base de Dados - **Heart Disease**:"
      ],
      "metadata": {
        "id": "5OG6jun6pw7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Permitir o google colab acessar os arquivos do Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Carregamento da base de dados a partir do Google Drive:\n",
        "caminho_arquivo = \"/content/drive/My Drive/heart.csv\"\n",
        "banco_de_dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "#Criar um Dataframe:\n",
        "heart_df = banco_de_dados\n",
        "\n",
        "#Preparar os dados:\n",
        "X = heart_df.drop('target', axis=1).to_numpy()\n",
        "y = heart_df['target'].to_numpy()\n",
        "\n",
        "#Normalizar os dados:\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#Dividir os dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "#Inicializar a matriz de probabilidades:\n",
        "num_classes = len(np.unique(y))\n",
        "probabilidadeDaClasse = np.zeros(num_classes)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    probabilidadeDaClasse[i] = len(indiceDaClasse[0]) / len(y_train)\n",
        "\n",
        "#Matriz para armazenar as probabilidades de classe para cada observação de teste:\n",
        "matrizProbabilidade = np.zeros((X_test.shape[0], num_classes))\n",
        "\n",
        "#Calcular as probabilidades de classe para as observações de teste:\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    dadosDeTreino = X_train[indiceDaClasse]\n",
        "    media = np.mean(dadosDeTreino, axis=0)\n",
        "    covariancia = np.cov(dadosDeTreino, rowvar=False)\n",
        "\n",
        "    for j in range(X_test.shape[0]):\n",
        "        observation = X_test[j]\n",
        "        matrizProbabilidade[j, i] = multivariate_normal.pdf(observation, mean=media, cov=covariancia, allow_singular=True) * probabilidadeDaClasse[i]\n",
        "\n",
        "#Prever as classes com base nas probabilidades:\n",
        "y_pred = np.argmax(matrizProbabilidade, axis=1)\n",
        "\n",
        "#Calcular a acurácia das previsões:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy:.4f}')\n",
        "\n",
        "#Gerar Matriz Confusão:\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1'])\n",
        "\n",
        "print(\"\\nMatriz de Confusao:\\n\", confusion)\n",
        "print(\"\\nRelatorio de Classificacao:\\n\", report)"
      ],
      "metadata": {
        "id": "F_BDAuSxlHU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste instante, serão desenvolvidos os códigos associados à fundamentação teórica **\"Naive Bayes\"**.\n",
        "\n",
        "Nesse viés, a biblioteca scikitlearn já dispobilizava determinadas funções, as quais facilitaram o processo de desenvolvimento do projeto."
      ],
      "metadata": {
        "id": "HqQiJHUTp6Qg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Base de Dados - **WINE**:"
      ],
      "metadata": {
        "id": "WKTMzzaBqFTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Carregar a base de dados Wine\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=13)\n",
        "\n",
        "# Criar um classificador Naive Bayes Gaussiano\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Treinar o classificador\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Avaliar o desempenho do classificador\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=wine.target_names)\n",
        "\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion)\n",
        "print(\"\\nRelatório de Classificação:\\n\", report)"
      ],
      "metadata": {
        "id": "iVuSJ46ApIMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Base de Dados - **Heart Disease**:"
      ],
      "metadata": {
        "id": "KIbPPoY-qJBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Permitir o google colab acessar os arquivos do Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Importar bibliotecas:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Carregamento da base de dados de doença cardíaca a partir do Google Drive:\n",
        "caminho_arquivo = \"/content/drive/My Drive/heart.csv\"  #Caminho correto para o arquivo no Google Drive.\n",
        "banco_de_dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "#Criar um Dataframe:\n",
        "heart_df = banco_de_dados\n",
        "\n",
        "#Armazenamento dos rótulos de classe em uma variável:\n",
        "heart_classe = heart_df['target']\n",
        "\n",
        "#Remoção da coluna 'target' do DataFrame, porque ela representa a variável de resposta ou saída do sistema e não deve ser usada como atributo de entrada para o modelo.\n",
        "heart_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "#Divisão dos dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(heart_df, heart_classe, test_size=0.3, random_state=13)\n",
        "\n",
        "#Criar um classificador Naive Bayes Gaussiano\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "#Treinar o classificador\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "#Fazer previsões no conjunto de teste\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "#Avaliar o desempenho do classificador\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1'])\n",
        "\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion)\n",
        "print(\"\\nRelatório de Classificação:\\n\", report)"
      ],
      "metadata": {
        "id": "fKGvJcyypKUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Referências:**\n",
        "LUIZ, E.; OLIVEIRA. **Reconhecimento de Padrões Teoria da Decisão Bayesiana**. [s.l: s.n.]. Disponível em: https://www.inf.ufpr.br/lesoliveira/padroes/\n",
        "decisaobayesiana.pdf. Acesso em: 5 de outubro de 2023.\n",
        "\n",
        "**Ciência de Dados: Teoria da Decisão Bayesiana na classificação de dados**.\n",
        "Disponível em: https://www.youtube.com/watch?v=8zAKWEOdGsg. Acesso em: 5 de\n",
        "outubro de 2023.\n",
        "\n",
        "**Data Mining Classification: Alternative Techniques**. Disponível em: https://\n",
        "www-users.cs.umn.edu/~kumar001/dmbook/slides/chap4_naive_bayes.pptx. Acesso\n",
        "em: 5 de outubro de 2023.\n",
        "\n",
        "OLIVEIRA, L. **Teorema de Bayes e Probabilidade**. Disponível em: https://\n",
        "medium.com/data-hackers/teorema-de-bayes-probabilidade-d5ead2df1379. Acesso\n",
        "em: 14 de outubro de 2023.\n",
        "\n",
        "OPENAI. **ChatGPT**. 2023. Disponível em: https://openai.com/ Acesso\n",
        "em: 15 de outubro de 2023.\n"
      ],
      "metadata": {
        "id": "VI6t8fFnrHbY"
      }
    }
  ]
}