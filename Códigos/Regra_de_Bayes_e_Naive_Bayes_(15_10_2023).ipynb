{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Atividade 4** - **Regra de Bayes** & **Naive Bayes** (15/10/2023)\n",
        "\n",
        "**Discente:** Vinícius Venceslau Venancio da Penha\n",
        "\n",
        "**Docente:** José Alfredo Ferreira Costa\n",
        "\n",
        "**ELE0606** - Tópicos Especiais em IA"
      ],
      "metadata": {
        "id": "UczsAzMhpX6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Base de Dados - **WINE**:"
      ],
      "metadata": {
        "id": "1GJL3pCKpqDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR62l9DZCxu4",
        "outputId": "3589a401-5740-4d16-8811-6c23842499ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.9722\n",
            "\n",
            "Matriz de Confusao:\n",
            " [[14  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  1  7]]\n",
            "\n",
            "Relatorio de Classificacao:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Classe 0       1.00      1.00      1.00        14\n",
            "    Classe 1       0.93      1.00      0.97        14\n",
            "    Classe 2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.96      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Carregar o conjunto de dados Wine:\n",
        "wine_data = load_wine()\n",
        "wine_df = pd.DataFrame(wine_data['data'], columns=wine_data['feature_names'])\n",
        "wine_df['classe'] = wine_data['target']  # Adicionar a coluna de classe\n",
        "\n",
        "#Preparar os dados:\n",
        "X = wine_df.drop('classe', axis=1).to_numpy()\n",
        "y = wine_df['classe'].to_numpy()\n",
        "\n",
        "#Normalizar os dados:\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#Dividir os dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Inicializar a matriz de probabilidades:\n",
        "num_classes = len(np.unique(y))\n",
        "probabilidadeDaClasse = np.zeros(num_classes)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    probabilidadeDaClasse[i] = len(indiceDaClasse[0]) / len(y_train)\n",
        "\n",
        "#Matriz para armazenar as probabilidades de classe para cada observação de teste:\n",
        "matrizProbabilidade = np.zeros((X_test.shape[0], num_classes))\n",
        "\n",
        "#Calcular as probabilidades de classe para as observações de teste:\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    dadosDeTreino = X_train[indiceDaClasse]\n",
        "    media = np.mean(dadosDeTreino, axis=0)\n",
        "    covariancia = np.cov(dadosDeTreino, rowvar=False)\n",
        "\n",
        "    for j in range(X_test.shape[0]):\n",
        "        observation = X_test[j]\n",
        "        matrizProbabilidade[j, i] = multivariate_normal.pdf(observation, mean=media, cov=covariancia, allow_singular=True) * probabilidadeDaClasse[i]\n",
        "\n",
        "#Prever as classes com base nas probabilidades:\n",
        "y_pred = np.argmax(matrizProbabilidade, axis=1)\n",
        "\n",
        "#Calcular a acurácia das previsões:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy:.4f}')\n",
        "\n",
        "#Gerar Matriz Confusao\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1', 'Classe 2'])\n",
        "\n",
        "print(\"\\nMatriz de Confusao:\\n\", confusion)\n",
        "print(\"\\nRelatorio de Classificacao:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Base de Dados - **Heart Disease**:"
      ],
      "metadata": {
        "id": "5OG6jun6pw7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Permitir o google colab acessar os arquivos do Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Carregamento da base de dados a partir do Google Drive:\n",
        "caminho_arquivo = \"/content/drive/My Drive/heart.csv\"\n",
        "banco_de_dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "#Criar um Dataframe:\n",
        "heart_df = banco_de_dados\n",
        "\n",
        "#Preparar os dados:\n",
        "X = heart_df.drop('target', axis=1).to_numpy()\n",
        "y = heart_df['target'].to_numpy()\n",
        "\n",
        "#Normalizar os dados:\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "#Dividir os dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "#Inicializar a matriz de probabilidades:\n",
        "num_classes = len(np.unique(y))\n",
        "probabilidadeDaClasse = np.zeros(num_classes)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    probabilidadeDaClasse[i] = len(indiceDaClasse[0]) / len(y_train)\n",
        "\n",
        "#Matriz para armazenar as probabilidades de classe para cada observação de teste:\n",
        "matrizProbabilidade = np.zeros((X_test.shape[0], num_classes))\n",
        "\n",
        "#Calcular as probabilidades de classe para as observações de teste:\n",
        "for i in range(num_classes):\n",
        "    indiceDaClasse = np.where(y_train == i)\n",
        "    dadosDeTreino = X_train[indiceDaClasse]\n",
        "    media = np.mean(dadosDeTreino, axis=0)\n",
        "    covariancia = np.cov(dadosDeTreino, rowvar=False)\n",
        "\n",
        "    for j in range(X_test.shape[0]):\n",
        "        observation = X_test[j]\n",
        "        matrizProbabilidade[j, i] = multivariate_normal.pdf(observation, mean=media, cov=covariancia, allow_singular=True) * probabilidadeDaClasse[i]\n",
        "\n",
        "#Prever as classes com base nas probabilidades:\n",
        "y_pred = np.argmax(matrizProbabilidade, axis=1)\n",
        "\n",
        "#Calcular a acurácia das previsões:\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy:.4f}')\n",
        "\n",
        "#Gerar Matriz Confusão:\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1'])\n",
        "\n",
        "print(\"\\nMatriz de Confusao:\\n\", confusion)\n",
        "print(\"\\nRelatorio de Classificacao:\\n\", report)"
      ],
      "metadata": {
        "id": "F_BDAuSxlHU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3babb533-0c91-46b5-cafa-1f64b48dbaee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Acurácia: 0.8537\n",
            "\n",
            "Matriz de Confusao:\n",
            " [[ 72  21]\n",
            " [  9 103]]\n",
            "\n",
            "Relatorio de Classificacao:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Classe 0       0.89      0.77      0.83        93\n",
            "    Classe 1       0.83      0.92      0.87       112\n",
            "\n",
            "    accuracy                           0.85       205\n",
            "   macro avg       0.86      0.85      0.85       205\n",
            "weighted avg       0.86      0.85      0.85       205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste instante, serão desenvolvidos os códigos associados à fundamentação teórica **\"Naive Bayes\"**.\n",
        "\n",
        "Nesse viés, a biblioteca scikitlearn já dispobilizava determinadas funções, as quais facilitaram o processo de desenvolvimento do projeto."
      ],
      "metadata": {
        "id": "HqQiJHUTp6Qg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Base de Dados - **WINE**:"
      ],
      "metadata": {
        "id": "WKTMzzaBqFTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Carregar a base de dados Wine\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=13)\n",
        "\n",
        "# Criar um classificador Naive Bayes Gaussiano\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Treinar o classificador\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Avaliar o desempenho do classificador\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=wine.target_names)\n",
        "\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion)\n",
        "print(\"\\nRelatório de Classificação:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVuSJ46ApIMW",
        "outputId": "b5d5bda6-8471-4c5a-b3cc-2f9a398cf965"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.9861111111111112\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[24  0  0]\n",
            " [ 0 30  1]\n",
            " [ 0  0 17]]\n",
            "\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        24\n",
            "     class_1       1.00      0.97      0.98        31\n",
            "     class_2       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.99        72\n",
            "   macro avg       0.98      0.99      0.99        72\n",
            "weighted avg       0.99      0.99      0.99        72\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Base de Dados - **Heart Disease**:"
      ],
      "metadata": {
        "id": "KIbPPoY-qJBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Permitir o google colab acessar os arquivos do Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Importar bibliotecas:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Carregamento da base de dados de doença cardíaca a partir do Google Drive:\n",
        "caminho_arquivo = \"/content/drive/My Drive/heart.csv\"  #Caminho correto para o arquivo no Google Drive.\n",
        "banco_de_dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "#Criar um Dataframe:\n",
        "heart_df = banco_de_dados\n",
        "\n",
        "#Armazenamento dos rótulos de classe em uma variável:\n",
        "heart_classe = heart_df['target']\n",
        "\n",
        "#Remoção da coluna 'target' do DataFrame, porque ela representa a variável de resposta ou saída do sistema e não deve ser usada como atributo de entrada para o modelo.\n",
        "heart_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "#Divisão dos dados em conjuntos de treinamento e teste:\n",
        "X_train, X_test, y_train, y_test = train_test_split(heart_df, heart_classe, test_size=0.3, random_state=13)\n",
        "\n",
        "#Criar um classificador Naive Bayes Gaussiano\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "#Treinar o classificador\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "#Fazer previsões no conjunto de teste\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "#Avaliar o desempenho do classificador\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Classe 0', 'Classe 1'])\n",
        "\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion)\n",
        "print(\"\\nRelatório de Classificação:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKGvJcyypKUY",
        "outputId": "6fdb7019-27d6-47c3-bdb8-674e4ad17024"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Acurácia: 0.814935064935065\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[113  39]\n",
            " [ 18 138]]\n",
            "\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Classe 0       0.86      0.74      0.80       152\n",
            "    Classe 1       0.78      0.88      0.83       156\n",
            "\n",
            "    accuracy                           0.81       308\n",
            "   macro avg       0.82      0.81      0.81       308\n",
            "weighted avg       0.82      0.81      0.81       308\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Referências:**\n",
        "LUIZ, E.; OLIVEIRA. **Reconhecimento de Padrões Teoria da Decisão Bayesiana**. [s.l: s.n.]. Disponível em: https://www.inf.ufpr.br/lesoliveira/padroes/\n",
        "decisaobayesiana.pdf. Acesso em: 5 de outubro de 2023.\n",
        "\n",
        "**Ciência de Dados: Teoria da Decisão Bayesiana na classificação de dados**.\n",
        "Disponível em: https://www.youtube.com/watch?v=8zAKWEOdGsg. Acesso em: 5 de\n",
        "outubro de 2023.\n",
        "\n",
        "**Data Mining Classification: Alternative Techniques**. Disponível em: https://\n",
        "www-users.cs.umn.edu/~kumar001/dmbook/slides/chap4_naive_bayes.pptx. Acesso\n",
        "em: 5 de outubro de 2023.\n",
        "\n",
        "OLIVEIRA, L. **Teorema de Bayes e Probabilidade**. Disponível em: https://\n",
        "medium.com/data-hackers/teorema-de-bayes-probabilidade-d5ead2df1379. Acesso\n",
        "em: 14 de outubro de 2023.\n",
        "\n",
        "OPENAI. **ChatGPT**. 2023. Disponível em: https://openai.com/ Acesso\n",
        "em: 15 de outubro de 2023.\n"
      ],
      "metadata": {
        "id": "VI6t8fFnrHbY"
      }
    }
  ]
}